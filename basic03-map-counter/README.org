# -*- fill-column: 76; -*-
#+TITLE: Tutorial: Basic03 - counting with BPF maps
#+OPTIONS: ^:nil

In this lesson you will learn about BPF maps, the persistent storage
mechanism available to BPF programs. The assignments will give you hands-on
experience with extending the "value" size/content, and reading the contents
from user space.

In this lesson we will only cover two simple maps types:
 - =BPF_MAP_TYPE_ARRAY= and
 - =BPF_MAP_TYPE_PERCPU_ARRAY=.

* Table of Contents                                                     :TOC:
- [[#things-you-will-learn-in-this-lesson][Things you will learn in this lesson]]
  - [[#defining-a-map][Defining a map]]
  - [[#libbpf-map-elf-relocation][libbpf map ELF relocation]]
  - [[#bpf_object-to-bpf_map][bpf_object to bpf_map]]
  - [[#reading-map-values-from-user-space][Reading map values from user space]]
- [[#helpful-example-commands][Helpful example commands]]
- [[#assignments][Assignments]]
  - [[#assignment-1-add-bytes-counter][Assignment 1: Add bytes counter]]
  - [[#assignment-2-handle-other-xdp-actions-stats][Assignment 2: Handle other XDP actions stats]]
  - [[#assignment-3-per-cpu-stats][Assignment 3: Per CPU stats]]

* Things you will learn in this lesson


** Defining a map

Creating a BPF map is done by defining a global struct (in
[[file:xdp_prog_kern.c]]), with a special =SEC(".maps")= as below:

#+begin_src C
struct {
	__uint(type, BPF_MAP_TYPE_ARRAY);
	__type(key, __u32);
	__type(value, struct datarec);
	__uint(max_entries, XDP_ACTION_MAX);
} xdp_stats_map SEC(".maps");
#+end_src

BPF maps are generic *key/value* stores (hence the =key= and =value= type
parameters), with a given map =type=, and maximum allowed entries
=max_entries=. Here we focus on the simple =BPF_MAP_TYPE_ARRAY=, which means
=max_entries= array elements get allocated when the map is first created.

The BPF map is accessible from both the BPF program (kernel) side and from
user space. How this is done and how they differ is part of this lesson.

** libbpf map ELF relocation

It is worth pointing out that everything goes through the bpf syscall. This
means that the user space program /must/ create the maps and programs with
separate invocations of the bpf syscall. So how does a BPF program reference
a BPF map?

This happens by first loading all the BPF maps, and storing their
corresponding file descriptors (FDs). Then the ELF relocation table is used
to identify each reference the BPF program makes to a given map; each such
reference is then rewritten, so the BPF byte code instructions use the right
map FD for each map.

All this needs to be done before the BPF program itself can be loaded into
the kernel. Fortunately, the libbpf library handles the ELF object decoding
and map reference relocation, transparently to the user space program
performing the loads.

** bpf_object to bpf_map

As you learned in [[file:../basic02-prog-by-name/][basic02]] the libbpf API have "objects" and functions
working on/with these objects. The struct =bpf_object= represents the ELF
object itself.

Similarly to what we did for BPF functions, our load has a function called
=find_map_fd()= (in [[file:xdp_load_and_stats.c]]), which uses the library
function =bpf_object__find_map_by_name()= for finding the =bpf_map= object
with a given name. (Note, the length of the map name is provided by ELF and
is longer than what the name kernel stores, after loading it). After finding
the =bpf_map=, we obtain the map file descriptor via =bpf_map__fd()=.
There is also a libbpf function that wraps these two steps, which is called
=bpf_object__find_map_fd_by_name()=.

** Reading map values from user space

The contents of a map is read from user space via the function
=bpf_map_lookup_elem()=, which is a simple syscall-wrapper, that operates on
the map file descriptor (FD). The syscall looks up the =key= and stores the
value into the memory area supplied by the value pointer. It is up to the
calling user space program to ensure that the memory allocated to hold the
returned value is large enough to store the type of data contained in the
map. In our example we demonstrate how user space can query the map FD and
get back some info in struct =bpf_map_info= via the syscall wrapper
=bpf_obj_get_info_by_fd()=.

For example, the program =xdp_load_and_stats= will periodically read the
xdp_stats_map value and produce some stats.

* Helpful example commands

#+begin_src sh
# Load the eBPF program to localhost interface
sudo ./xdp_load_and_stats --dev lo

# Unload eBPF program from localhost interface
sudo ./xdp_load_and_stats --dev lo --unload-all

# Receive data from localhost port 12345
ncat -lk 127.0.0.1 12345

# Send data to localhost port 12345 
printf 'hello from sender\n' | nc 127.0.0.1 12345
#+end_src

* Assignments

The assignments have "hint" marks in the code via =Assignment#num=
comments.

** Assignment 1: Add bytes counter

The current assignment code only counts packets.  It is your *assignment* to
extend this to also count bytes.

Notice how the BPF map =xdp_stats_map= used:
 - =.value_size = sizeof(struct datarec)=

The BPF map has no knowledge about the data-structure used for the value
record, it only knows the size. (The [[https://github.com/torvalds/linux/blob/master/Documentation/bpf/btf.rst][BPF Type Format]] ([[https://www.kernel.org/doc/html/latest/bpf/btf.html][BTF]]) is an advanced
topic, that allows for associating data struct knowledge via debug info, but
we ignore that for now). Thus, it is up to the two sides (user space and
BPF-prog kernel side) to ensure they stay in sync on the content and
structure of =value=. The hint here on the data structure used comes from
=sizeof(struct datarec)=, which indicate that =struct datarec= is used.

This =struct datarec= is defined in the include [[file:common_kern_user.h]] as:

#+begin_src C
/* This is the data record stored in the map */
struct datarec {
	__u64 rx_packets;
	/* Assignment#1: Add byte counters */
};
#+end_src

*** Assignment 1.1: Update the BPF program

Next step is to update the kernel side BPF program: [[file:xdp_prog_kern.c]].

To figure out the length of the packet, you need to learn about the context
variable =*ctx= with type [[https://elixir.bootlin.com/linux/v5.0/ident/xdp_md][struct xdp_md]] that the BPF program gets a pointer
to when invoked by the kernel. This =struct xdp_md= is a little odd, as all
members have type =__u32=. However, this is not actually their real data
types, as access to this data-structure is remapped by the kernel when the
program is loaded into the kernel. Access gets remapped to struct =xdp_buff=
and also struct =xdp_rxq_info=.

#+begin_src C
struct xdp_md {
	// (Note: type __u32 is NOT the real-type)
	__u32 data;
	__u32 data_end;
	__u32 data_meta;
	/* Below access go through struct xdp_rxq_info */
	__u32 ingress_ifindex; /* rxq->dev->ifindex */
	__u32 rx_queue_index;  /* rxq->queue_index */
};
#+end_src

While we know this, the compiler doesn't. So we need to type-cast the fields
into void pointers before we can use them:

#+begin_src C
	void *data_end = (void *)(long)ctx->data_end;
	void *data     = (void *)(long)ctx->data;
#+end_src

The next step is calculating the number of bytes in each packet, by simply
subtracting =data= from =data_end=, and update the datarec member.

#+begin_src C
	__u64 bytes = data_end - data; /* Calculate packet length */
	lock_xadd(&rec->rx_bytes, bytes);
#+end_src

*** Assignment 1.2: Update the user space program

Now it is time to update the user space program that reads stats (in
[[file:xdp_load_and_stats.c]]).

Update the functions:
 - =map_collect()= to also collect rx_bytes.
 - =stats_print()= to also print rx_bytes (adjust fmt string)

** Assignment 2: Handle other XDP actions stats

Notice how the BPF map =xdp_stats_map= we defined above is actually an
array, with =max_entries=XDP_ACTION_MAX=. The idea with this is to keep
stats per [[https://elixir.bootlin.com/linux/latest/ident/xdp_action][(enum) xdp_action]], but our program does not yet take advantage of
this.

The *assignment* is to extend user space stats tool (in
[[file:xdp_load_and_stats.c]]) to collect and print these extra stats.

** Assignment 3: Per CPU stats

Thus far, we have used atomic operations to increment our stats counters;
however, this is expensive as it inserts memory barriers to make sure
different CPUs don't garble each other's data. We can avoid this by using
another array type that stores its data in per-CPU storage. The drawback of
this is that we move the burden of summing to user space.

To achieve this, the first step is to change map =type= (in
[[file:xdp_prog_kern.c]]) to use =BPF_MAP_TYPE_PERCPU_ARRAY=. If you only make
this change, the user space program will detect this and complain, as we
query the map FD for some info (via =bpf_obj_get_info_by_fd()=) and e.g.
check the map type. Remember it is user space's responsibility to make sure
the data record for the value is large enough.

Next step is writing a function that gets the values per CPU and sum these.
In the [[file:xdp_load_and_stats.c]]. You can copy paste this, and call it from
the switch-case statement in function =map_collect()=:

#+begin_src C
/* BPF_MAP_TYPE_PERCPU_ARRAY */
void map_get_value_percpu_array(int fd, __u32 key, struct datarec *value)
{
	/* For percpu maps, user space gets a value per possible CPU */
	unsigned int nr_cpus = libbpf_num_possible_cpus();
	struct datarec values[nr_cpus];
	__u64 sum_bytes = 0;
	__u64 sum_pkts = 0;
	int i;

	if ((bpf_map_lookup_elem(fd, &key, values)) != 0) {
		fprintf(stderr,
			"ERR: bpf_map_lookup_elem failed key:0x%X\n", key);
		return;
	}

	/* Sum values from each CPU */
	for (i = 0; i < nr_cpus; i++) {
		sum_pkts  += values[i].rx_packets;
		sum_bytes += values[i].rx_bytes;
	}
	value->rx_packets = sum_pkts;
	value->rx_bytes   = sum_bytes;
}
#+end_src
